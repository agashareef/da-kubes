---
AWSTemplateFormatVersion: 2010-09-09
Description: Amazon EKS - Distributed Automation Baseline cluster
Parameters:
  EKSClusterName:
    Default: DA-Kube
    Type: String

  Ec2InstanceType:
    AllowedValues:
      - c5.large
      - c5.xlarge
      - c5.2xlarge
      - c5.4xlarge
      - c5.9xlarge
      - c5.18xlarge
      - i3.large
      - i3.xlarge
      - i3.2xlarge
      - i3.4xlarge
      - i3.8xlarge
      - i3.16xlarge
      - m4.large
      - m4.xlarge
      - m4.2xlarge
      - m4.4xlarge
      - m4.10xlarge
      - r4.xlarge
      - r4.2xlarge
      - r4.4xlarge
      - m5.large
      - m5.xlarge
      - m5.2xlarge
      - m5.4xlarge
      - m5.12xlarge
      - m5.24xlarge
      - t2.small
      - t2.medium
      - t2.large
      - t2.xlarge
      - t2.2xlarge
    Default: r4.2xlarge
    Description: EC2 instance type
    Type: String

  KeyName:
    Default: defaultkey
    Description: The EC2 Key Pair to allow SSH access to the instances
    Type: AWS::EC2::KeyPair::KeyName

  NodeGroupName:
    Default: worker
    Type: String

Mappings:
  # Test Account-Region Mappings
  # AWS Account Number
  '123456789012':
    activedirectory:
      config: test
    us-west-2:
      Ec2SubnetIds:
        - subnet-xxxxx
        - subnet-xxxxx
      VpcId: vpc-xxxxx
      NodeAutoScalingGroupMinSize: 1
      NodeAutoScalingGroupMaxSize: 40
      NodeAutoScalingDesiredCapacity: 2

  # Region Mappings
  RegionMap:
    us-east-1:
      NodeImageId: ami-xxxx
    us-west-2:
      NodeImageId: ami-xxxxxx

  MaxPodsPerNode:
    c5.large:
      MaxPods: 15
    c5.xlarge:
      MaxPods: 9
    c5.2xlarge:
      MaxPods: 58
    c5.4xlarge:
      MaxPods: 234
    c5.9xlarge:
      MaxPods: 234
    c5.18xlarge:
      MaxPods: 737
    i3.large:
      MaxPods: 29
    i3.xlarge:
      MaxPods: 58
    i3.2xlarge:
      MaxPods: 58
    i3.4xlarge:
      MaxPods: 234
    i3.8xlarge:
      MaxPods: 234
    i3.16xlarge:
      MaxPods: 737
    m4.large:
      MaxPods: 20
    m4.xlarge:
      MaxPods: 58
    m4.2xlarge:
      MaxPods: 58
    m4.4xlarge:
      MaxPods: 234
    m4.10xlarge:
      MaxPods: 234
    m5.large:
      MaxPods: 29
    m5.xlarge:
      MaxPods: 58
    m5.2xlarge:
      MaxPods: 58
    m5.4xlarge:
      MaxPods: 234
    m5.12xlarge:
      MaxPods: 234
    m5.24xlarge:
      MaxPods: 737
    p2.xlarge:
      MaxPods: 58
    p2.8xlarge:
      MaxPods: 234
    p2.16xlarge:
      MaxPods: 234
    p3.2xlarge:
      MaxPods: 58
    p3.8xlarge:
      MaxPods: 234
    p3.16xlarge:
      MaxPods: 234
    r4.large:
      MaxPods: 29
    r4.xlarge:
      MaxPods: 58
    r4.2xlarge:
      MaxPods: 58
    r4.4xlarge:
      MaxPods: 234
    r4.8xlarge:
      MaxPods: 234
    r4.16xlarge:
      MaxPods: 737
    t2.small:
      MaxPods: 8
    t2.medium:
      MaxPods: 17
    t2.large:
      MaxPods: 35
    t2.xlarge:
      MaxPods: 44
    t2.2xlarge:
      MaxPods: 44
    x1.16xlarge:
      MaxPods: 234
    x1.32xlarge:
      MaxPods: 234

Resources:
  ControlPlaneSecurityGroup:
    Type: AWS::EC2::SecurityGroup
    Properties:
      GroupDescription: !Join ['-', [!Ref 'EKSClusterName', 'EKS cluster communication with worker nodes']]
      VpcId: !FindInMap [!Ref 'AWS::AccountId', !Ref 'AWS::Region', VpcId]

  EKSServiceRole:
    Type: AWS::IAM::Role
    Properties:
      AssumeRolePolicyDocument:
        Version: '2012-10-17'
        Statement:
          - Effect: Allow
            Principal:
              Service:
                - eks.amazonaws.com
            Action:
              - sts:AssumeRole
      Path: '/'
      ManagedPolicyArns:
        - arn:aws:iam::aws:policy/AmazonEKSClusterPolicy
        - arn:aws:iam::aws:policy/AmazonEKSServicePolicy

  EKSCluster:
    Type: AWS::EKS::Cluster
    Properties:
      Name: !Ref EKSClusterName
      ResourcesVpcConfig:
        SecurityGroupIds: !Split [" ", !Ref ControlPlaneSecurityGroup]
        SubnetIds: !FindInMap [!Ref 'AWS::AccountId', !Ref 'AWS::Region', Ec2SubnetIds]
      RoleArn: !GetAtt EKSServiceRole.Arn
      Version: '1.11'
    DependsOn:
      - ControlPlaneSecurityGroup
      - EKSServiceRole

  NodeInstanceProfile:
    Type: AWS::IAM::InstanceProfile
    Properties:
      Path: "/"
      Roles:
        - !Ref NodeInstanceRole

  NodeInstanceRole:
    Type: AWS::IAM::Role
    Properties:
      AssumeRolePolicyDocument:
        Version: '2012-10-17'
        Statement:
          - Effect: Allow
            Principal:
              Service:
                - ec2.amazonaws.com
            Action:
              - sts:AssumeRole
      Path: "/"
      ManagedPolicyArns:
        - arn:aws:iam::aws:policy/AmazonEKSWorkerNodePolicy
        - arn:aws:iam::aws:policy/AmazonEKS_CNI_Policy
        - arn:aws:iam::aws:policy/AmazonEC2ContainerRegistryReadOnly

  ClusterAutoscalerPolicy:
    Type: AWS::IAM::Policy
    Properties:
      PolicyName: !Sub "${EKSClusterName}AutoscalerPolicy"
      PolicyDocument:
        Version: '2012-10-17'
        Statement:
          Action:
            - autoscaling:DescribeAutoScalingGroups
            - autoscaling:DescribeAutoScalingInstances
            - autoscaling:DescribeTags
            - autoscaling:SetDesiredCapacity
            - autoscaling:TerminateInstanceInAutoScalingGroup
          Effect: Allow
          Resource: "*"
      Roles: [!Ref NodeInstanceRole]

  NodeSecurityGroup:
    Type: AWS::EC2::SecurityGroup
    Properties:
      GroupDescription: Security group for all nodes in the cluster and ssh
      VpcId: !FindInMap [!Ref 'AWS::AccountId', !Ref 'AWS::Region', VpcId]
      Tags:
        - Key: !Sub "kubernetes.io/cluster/${EKSClusterName}"
          Value: 'owned'
      SecurityGroupIngress:
      - IpProtocol: tcp
        FromPort: 1025
        ToPort: 65535
        CidrIp: x.x.x.x/x
        Description: kubectl access
      - IpProtocol: tcp
        FromPort: 22
        ToPort: 22
        CidrIp: x.x.x.x/x
        Description: ssh access

  NodeSecurityGroupIngress:
    Type: AWS::EC2::SecurityGroupIngress
    DependsOn: NodeSecurityGroup
    Properties:
      Description: !Join ['-', [!Ref 'EKSClusterName', Allow node to communicate with each other]]
      GroupId: !Ref NodeSecurityGroup
      SourceSecurityGroupId: !Ref NodeSecurityGroup
      IpProtocol: '-1'
      FromPort: 0
      ToPort: 65535

  NodeSecurityGroupFromControlPlaneIngress:
    Type: AWS::EC2::SecurityGroupIngress
    DependsOn: NodeSecurityGroup
    Properties:
      Description: !Join ['-', [!Ref 'EKSClusterName', Allow worker Kubelets and pods to receive communication from the cluster control plane]]
      GroupId: !Ref NodeSecurityGroup
      SourceSecurityGroupId: !Ref ControlPlaneSecurityGroup
      IpProtocol: tcp
      FromPort: 1025
      ToPort: 65535

  ControlPlaneEgressToNodeSecurityGroup:
    Type: AWS::EC2::SecurityGroupEgress
    DependsOn: NodeSecurityGroup
    Properties:
      Description: !Join ['-', [!Ref 'EKSClusterName', Allow the cluster control plane to communicate with worker Kubelet and pods]]
      GroupId: !Ref ControlPlaneSecurityGroup
      DestinationSecurityGroupId: !Ref NodeSecurityGroup
      IpProtocol: tcp
      FromPort: 1025
      ToPort: 65535

  ClusterControlPlaneSecurityGroupIngress:
    Type: AWS::EC2::SecurityGroupIngress
    DependsOn: NodeSecurityGroup
    Properties:
      Description: !Join ['-', [!Ref 'EKSClusterName', Allow pods to communicate with the cluster API Server]]
      GroupId: !Ref ControlPlaneSecurityGroup
      SourceSecurityGroupId: !Ref NodeSecurityGroup
      IpProtocol: tcp
      ToPort: 443
      FromPort: 443

  NodeGroup:
    Type: AWS::AutoScaling::AutoScalingGroup
    Properties:
      DesiredCapacity: !FindInMap [!Ref 'AWS::AccountId', !Ref 'AWS::Region', NodeAutoScalingDesiredCapacity]
      LaunchConfigurationName: !Ref NodeLaunchConfig
      MinSize: !FindInMap [!Ref 'AWS::AccountId', !Ref 'AWS::Region', NodeAutoScalingGroupMinSize]
      MaxSize: !FindInMap [!Ref 'AWS::AccountId', !Ref 'AWS::Region', NodeAutoScalingGroupMaxSize]
      VPCZoneIdentifier:
        !FindInMap [!Ref 'AWS::AccountId', !Ref 'AWS::Region', Ec2SubnetIds]
      Tags:
        - Key: Name
          Value: !Sub "${EKSClusterName}-${NodeGroupName}-Node"
          PropagateAtLaunch: 'true'
        - Key: !Sub 'kubernetes.io/cluster/${EKSClusterName}'
          Value: 'owned'
          PropagateAtLaunch: 'true'
        - Key: !Sub 'k8s.io/cluster-autoscaler/enabled'
          Value: 'owned'
          PropagateAtLaunch: 'true'
        - Key: !Sub 'k8s.io/cluster-autoscaler/${EKSClusterName}'
          Value: 'owned'
          PropagateAtLaunch: 'true'
    UpdatePolicy:
      AutoScalingRollingUpdate:
        MinInstancesInService: !FindInMap [!Ref 'AWS::AccountId', !Ref 'AWS::Region', NodeAutoScalingDesiredCapacity]
        MaxBatchSize: '1'
        PauseTime: "PT2M0S"
        WaitOnResourceSignals: "true"
    DependsOn:
      - EKSCluster

  NodeLaunchConfig:
    Type: AWS::AutoScaling::LaunchConfiguration
    Properties:
      AssociatePublicIpAddress: false
      IamInstanceProfile: !Ref NodeInstanceProfile
      ImageId: !FindInMap [RegionMap, !Ref "AWS::Region", NodeImageId]
      InstanceType: !Ref Ec2InstanceType
      KeyName: !Ref KeyName
      SecurityGroups:
        - !Ref NodeSecurityGroup
      UserData:
        Fn::Base64:
          Fn::Join: [
          "",
            [
              "#!/bin/bash -xe\n",
              "# Version: 1.0", "\n",
              "CA_CERTIFICATE_DIRECTORY=/etc/kubernetes/pki", "\n",
              "CA_CERTIFICATE_FILE_PATH=$CA_CERTIFICATE_DIRECTORY/ca.crt", "\n",
              "MODEL_DIRECTORY_PATH=~/.aws/eks", "\n",
              "MODEL_FILE_PATH=$MODEL_DIRECTORY_PATH/eks-2017-11-01.normal.json", "\n",
              "mkdir -p $CA_CERTIFICATE_DIRECTORY", "\n",
              "mkdir -p $MODEL_DIRECTORY_PATH", "\n",
              "/usr/bin/hostnamectl set-hostname $(curl -s http://169.254.169.254/latest/meta-data/hostname | cut -d' ' -f1)", "\n",
              "curl -o $MODEL_FILE_PATH https://s3-us-west-2.amazonaws.com/amazon-eks/1.10.3/2018-06-05/eks-2017-11-01.normal.json", "\n",
              "aws configure add-model --service-model file://$MODEL_FILE_PATH --service-name eks", "\n",
              "aws eks describe-cluster --region=", {Ref: "AWS::Region"}, " --name=", {Ref: EKSClusterName}, " --query 'cluster.{certificateAuthorityData: certificateAuthority.data, endpoint: endpoint}' > /tmp/describe_cluster_result.json", "\n",
              "cat /tmp/describe_cluster_result.json | grep certificateAuthorityData | awk '{print $2}' | sed 's/[,\"]//g' | base64 -d >  $CA_CERTIFICATE_FILE_PATH", "\n",
              "MASTER_ENDPOINT=$(cat /tmp/describe_cluster_result.json | grep endpoint | awk '{print $2}' | sed 's/[,\"]//g')", "\n",
              "INTERNAL_IP=$(curl -s http://169.254.169.254/latest/meta-data/local-ipv4)", "\n",
              "sed -i s,MASTER_ENDPOINT,$MASTER_ENDPOINT,g /var/lib/kubelet/kubeconfig", "\n",
              "sed -i s,CLUSTER_NAME,", {Ref: EKSClusterName}, ",g /var/lib/kubelet/kubeconfig", "\n",
              "sed -i s,REGION,", {Ref: "AWS::Region"}, ",g /etc/systemd/system/kubelet.service", "\n",
              "sed -i s,MAX_PODS,", {"Fn::FindInMap": [MaxPodsPerNode, {Ref: Ec2InstanceType}, MaxPods]}, ",g /etc/systemd/system/kubelet.service", "\n",
              "sed -i s,MASTER_ENDPOINT,$MASTER_ENDPOINT,g /etc/systemd/system/kubelet.service", "\n",
              "sed -i s,INTERNAL_IP,$INTERNAL_IP,g /etc/systemd/system/kubelet.service", "\n",
              "DNS_CLUSTER_IP=10.100.0.10", "\n",
              "if [[ $INTERNAL_IP == 10.* ]] ; then DNS_CLUSTER_IP=172.20.0.10; fi", "\n",
              "sed -i s,DNS_CLUSTER_IP,$DNS_CLUSTER_IP,g  /etc/systemd/system/kubelet.service", "\n",
              "sed -i s,CERTIFICATE_AUTHORITY_FILE,$CA_CERTIFICATE_FILE_PATH,g /var/lib/kubelet/kubeconfig", "\n",
              "sed -i s,CLIENT_CA_FILE,$CA_CERTIFICATE_FILE_PATH,g  /etc/systemd/system/kubelet.service", "\n",
              "sed -i '/ExecStart/a\ \  --eviction-hard=memory.available<768Mi  \\\\' /etc/systemd/system/kubelet.service", "\n",
              "sed -i '/ExecStart/a\ \  --system-reserved=memory=1536Mi \\\\' /etc/systemd/system/kubelet.service", "\n",
              "sed -i '/ExecStart/a\ \  --kube-reserved=memory=1536Mi \\\\' /etc/systemd/system/kubelet.service", "\n",
              "sed -i -e 's/Restart=on-failure/Restart=Always/g' /etc/systemd/system/kubelet.service" ,"\n",
              "sed -i -e 's/RestartSec=5/RestartSec=30/g' /etc/systemd/system/kubelet.service" ,"\n",
              "systemctl daemon-reload", "\n",
              "systemctl restart kubelet", "\n",
              "/opt/aws/bin/cfn-signal -e $? ",
              "         --stack ", {Ref: "AWS::StackName"},
              "         --resource NodeGroup ",
              "         --region ", {Ref: "AWS::Region"}, "\n"
            ]
          ]
Outputs:
  KubeSecurityGroups:
    Description: Security group for the cluster control plane communication with worker nodes
    Value: !Ref ControlPlaneSecurityGroup

  KubeServiceRole:
    Description: The control plane service role
    Value: !GetAtt EKSServiceRole.Arn

  KubeArn:
    Description: EKS cluster resource name
    Value: !GetAtt EKSCluster.Arn

  KubeCA:
    Description: EKS cluster CA certificate
    Value: !GetAtt EKSCluster.CertificateAuthorityData

  KubeUrl:
    Description: EKS cluster endpoint
    Value: !GetAtt EKSCluster.Endpoint

  NodeInstanceRole:
    Description: The node instance role
    Value: !GetAtt NodeInstanceRole.Arn
